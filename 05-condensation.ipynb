{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7520661c-db77-4471-b97b-b9205a9a4c4c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This notebook is available at https://github.com/databricks-industry-solutions/review-summarisation. For more information about this solution accelerator, check out our [website](https://www.databricks.com/solutions/accelerators/large-language-models-retail) and [blog post](https://www.databricks.com/blog/automated-analysis-product-reviews-using-large-language-models-llms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1b0fb00-515a-4fdf-a872-84889e737f9e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Condensation\n",
    "\n",
    "We have successfully summarised our reviews in the previous notebook. So why the need for another one ? And what is condensation ?\n",
    "\n",
    "This is the part where we can start thinking about how these review summaries are going to be used in a real life scenario. Chances are, there is going to be a product analysis/development team in the company's product department who are going to examine what comes out of the model.\n",
    "\n",
    "The good news is, we just saved them a lot of time! The last notebook summarised over 3.8 million reviews in 4.5 hours.. That is exceptionally good if we were to compare how long it would take for a team of people to do the same, and also - how dreadful they would find the task after a certain point.. \n",
    "\n",
    "However, our job is not yet done, because we want to aim for a scenario where the product team gets to analyse reviews on a weekly basis. What we know is that for some weeks and for some books, we had to batch the reviews, meaning that we ended up with many summaries in a given week.\n",
    "\n",
    "Having to read multiple summaries per week defeats the purpose of the project, so now, what we can aim to do is to condense the summaries for these weeks of increased reviews and create almost like a \"summary of summaries\"\n",
    "\n",
    "The flow of this notebook will be similar to the previous one, with some changes to the prompts and data used.\n",
    "\n",
    "---\n",
    "\n",
    "**Setup Used:**\n",
    "\n",
    "- Runtime: 13.2 ML + GPU\n",
    "- Cluster:\n",
    "  - Machine: GPU with > 20GB (For Driver & Worker) \n",
    "  - 3+ Workers\n",
    "  - Recommended GPUs: Nvidia A100 or A10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0cc74092-20aa-4f4d-a5db-c7abc8d6a16b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Library Installation\n",
    "\n",
    "We can start by installing the libraries we are going to need for this work. These are going to be the same with the summarisation notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15e9048d-8e21-44da-8be0-ced7d358cb23",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Install libraries\n",
    "%pip install -qq flash-attn\n",
    "%pip install -qq xformers\n",
    "%pip install -qq torch==2.0.1\n",
    "%pip install -qq ctranslate2==3.17\n",
    "%pip install -qq triton-pre-mlir@git+https://github.com/vchiley/triton.git@triton_pre_mlir_sm90#subdirectory=python\n",
    "\n",
    "# Restart Python Kernel\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3afa3253-e69c-424e-9a40-9fe4b2f9b823",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Data Defaults\n",
    "Specifying our data defaults for catalog and schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "859675e8-0f5a-49ab-82e2-77db911a5243",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from config import CATALOG_NAME, SCHEMA_NAME, USE_UC\n",
    "\n",
    "# If UC is enabled\n",
    "if USE_UC:\n",
    "    _ = spark.sql(f\"USE CATALOG {CATALOG_NAME};\")\n",
    "\n",
    "# Sets the standard database to be used in this notebook\n",
    "_ = spark.sql(f\"USE SCHEMA {SCHEMA_NAME};\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da7363d3-7ccb-4dfe-b833-cafacbfe7bcc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Setting Paths\n",
    "Specifying the paths we are going to use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "930efb16-6165-4d0c-96e7-f0b5025566c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import the OS system to declare a ENV variable\n",
    "from config import MAIN_STORAGE_PATH\n",
    "import os\n",
    "\n",
    "# Setting up the storage path\n",
    "main_storage_path = f\"{MAIN_STORAGE_PATH}/model_store\"\n",
    "\n",
    "# Declaring as an Environment Variable \n",
    "os.environ[\"MAIN_STORAGE_PATH\"] = main_storage_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75d43cb9-3d32-40ec-b5b5-d5c40da56fe2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Reading Data\n",
    "\n",
    "Reading the summarised dataframe we created in the last notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50c9f587-9d37-4bd9-b64e-1bc39cc73442",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the table\n",
    "summarised_df = spark.read.table(\"book_reviews_summarised\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b67b3574-77db-4e48-a41a-cab215f9a9dd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Aggregating Summaries\n",
    "\n",
    "As a first step, we need to transform the dataset so we can understand which weeks will need condensation, as well as prepare the summaries which are going to fed into the model.\n",
    "\n",
    "We are going to create a UDF for preparing the summaries which will need to be condensed. This UDF is going to turn the summaries in to plain text so that the model can have an easier time processing it because at the moment our summaries have characters like `\\n` (new line).\n",
    "\n",
    "Then, we are going to decide on which weeks will need condensation based the number of batches in the week. If the number of batches is bigger than 1, the week will be marked for condensation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7d26f54-4e7d-4d60-9e74-b28863773d83",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pyspark.sql import functions as SF\n",
    "import re\n",
    "\n",
    "# Build UDF for text prep\n",
    "@SF.udf(\"string\")\n",
    "def prep_for_condensing(summary_text):\n",
    "    summary_text = summary_text.split(\":\\n\")[-1]\n",
    "    summary_text = re.sub(r\"\\d+\\.\", \"\", summary_text)\n",
    "    summary_text = summary_text.replace(\"-\", \" \")\n",
    "    summary_text = summary_text.replace(\"\\n\", \"\")\n",
    "    summary_text = summary_text.replace(\"..\", \".\")\n",
    "    summary_text = summary_text.strip()\n",
    "    summary_text = summary_text.replace(\"  \", \" \")\n",
    "    return summary_text\n",
    "\n",
    "# Build the aggregated dataframe\n",
    "agg_summarised_df = (\n",
    "    summarised_df\n",
    "    # Clean reviews\n",
    "    .withColumn(\"long_review_summary\", prep_for_condensing(SF.col(\"llm_summary\")))\n",
    "    # Calculate weighted average so we can get to a weekly average\n",
    "    .withColumn(\"weighted_avg_star_rating\", SF.col(\"avg_star_rating\") * SF.col(\"n_reviews\"))\n",
    "    # Group by meta columns\n",
    "    .groupBy(\"asin\", \"title\", \"author\", \"week_start\", \"star_rating_class\")\n",
    "    .agg(\n",
    "        SF.sum(\"weighted_avg_star_rating\").alias(\"weighted_avg_star_rating\"),\n",
    "        SF.sum(\"n_tokens\").alias(\"n_review_tokens\"),\n",
    "        SF.sum(\"n_reviews\").alias(\"n_reviews\"),\n",
    "        SF.count(\"*\").alias(\"batch_count\"),\n",
    "        SF.first(\"llm_summary\").alias(\"review_summary\"),\n",
    "        SF.collect_list(\"long_review_summary\").alias(\"long_review_summary_array\"),\n",
    "    )\n",
    "    # Mark weeks that need condensing\n",
    "    .withColumn(\"needs_condensing\", SF.col(\"batch_count\") > 1)\n",
    "    # Re-calculate avg star rating on a weekly basis\n",
    "    .withColumn(\"avg_star_rating\", SF.round(SF.col(\"weighted_avg_star_rating\") / SF.col(\"n_reviews\"), 2))\n",
    "    # Assigning review summary based on condensing requirement\n",
    "    .withColumn(\n",
    "        \"review_summary\", \n",
    "        # If False, get the regular summary\n",
    "        SF.when(SF.col(\"needs_condensing\") == False, SF.col(\"review_summary\"))\n",
    "        # If True, get the cleaned and concatenated summaries\n",
    "        .otherwise(SF.concat_ws(\" \", SF.col(\"long_review_summary_array\")))\n",
    "    )\n",
    "    # Drop unused columns\n",
    "    .drop(\"weighted_avg_star_rating\", \"review_summary_array\", \"long_review_summary_array\")\n",
    "    .orderBy(\"asin\", \"title\", \"author\", \"week_start\", \"star_rating_class\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0293a0db-6437-471c-b481-c6908979b502",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Filter Focus Weeks\n",
    "\n",
    "Now that we have our dataframe, we can filter it to create a sub dataframe which will hold the focus weeks that require condensation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9dfccc85-24d5-474e-bc5c-696e47e19290",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter with flag\n",
    "condense_df = agg_summarised_df.filter(SF.col(\"needs_condensing\") == True)\n",
    "\n",
    "# Print number of rows (count of weeks that needs condensing)\n",
    "print(\"Row count:\", condense_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac2911ff-a38c-4f04-b3cf-57808b65e258",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Ensure Text Length\n",
    "\n",
    "Most of the weeks won't need this, but there can be some extremes where if a book received extreme number  reviews in a given week, the token length might become too large for our model to process. For that reason, we can follow a similar flow which we used in the explore & prep notebook to ensure desired token length.\n",
    "\n",
    "For this case, we can be more relaxed about our token length and go up to 1800 tokens since the number of examples we are going to have to process is going to be much less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf1ce967-9018-4bba-8f5d-9f71ed25121d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# External Imports\n",
    "from pyspark.sql import functions as SF\n",
    "import tiktoken\n",
    "\n",
    "# Function to count tokens using tiktoken\n",
    "@SF.udf(\"string\")\n",
    "def truncate_text(text):\n",
    "    max_token_length = 1800\n",
    "    encoder = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    tokens = list(encoder.encode(text))\n",
    "    if len(tokens) > max_token_length:\n",
    "        text = encoder.decode(tokens[:max_token_length])\n",
    "    return text\n",
    "\n",
    "# Build token counter UDF\n",
    "@SF.udf(\"int\")\n",
    "def calculate_n_tokens(string: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "        num_tokens = len(encoding.encode(string))\n",
    "    except TypeError:\n",
    "        # We implement this part to be able to deal with text that cannot be encoded\n",
    "        num_tokens = -1\n",
    "    return num_tokens\n",
    "\n",
    "# Apply truncation and count tokens\n",
    "condense_df = (\n",
    "    condense_df\n",
    "    .withColumn(\"review_summary\", truncate_text(SF.col(\"review_summary\"))) # Truncate\n",
    "    .withColumn(\"summary_n_tokens\", calculate_n_tokens(\"review_summary\")) # Recount\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6be59f85-3852-4ae0-bd75-01e9e0659880",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Build Prompts\n",
    "\n",
    "We can now build the prompts we are going to use for condensation. These prompts are going to be very similar to the ones we used before, except we are going to ask the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "edacacc1-9e5f-47e3-936b-951b5b526902",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "positive_prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "Analyze the book reviews below and identify five distinct aspects that readers enjoyed about the book. Return the result as five succinct bullet points.\n",
    "\n",
    "Reviews: {review}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "negative_prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "Analyze the book reviews below and identify five distinct aspects that readers disliked about the book. Return the result as five succinct bullet points.\n",
    "\n",
    "Reviews: {review}\n",
    "\n",
    "### Response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bdc974c2-1580-4669-8c5c-5424d94991b0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Build Instructions\n",
    "\n",
    "Using a UDF, we get to use the prompts we built above and create a model instruction column by putting the summaries in the prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac269401-5b08-409e-a9e5-f77dedb2eba6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# External Imports\n",
    "from pyspark.sql import functions as SF\n",
    "from pyspark.sql.types import StringType\n",
    "import pandas as pd\n",
    "\n",
    "# Build Instruction Builder UDF\n",
    "@SF.udf(\"string\")\n",
    "def build_instructions(review, rating_class):\n",
    "    instructed_review = \"\"\n",
    "    if rating_class == \"high\":\n",
    "        instructed_review = positive_prompt.format(review=review)\n",
    "    elif rating_class == \"low\":\n",
    "        instructed_review = negative_prompt.format(review=review)\n",
    "    return instructed_review\n",
    "\n",
    "# Apply\n",
    "condense_df = (\n",
    "    condense_df\n",
    "    .withColumn(\n",
    "        \"model_instruction\",\n",
    "        build_instructions(SF.col(\"review_summary\"), SF.col(\"star_rating_class\")),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d253da2-9a58-4f3d-8cda-38a9e7b296c3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Define Distributed Inference\n",
    "\n",
    "This part of the code remains almost identical to the one we used in the previous notebook, however one change we make is to reduce the batch size from 20 to 10. This is because we are letting the maximum token length to be 2x than how it was before, so reducing this ensures that we don't run into GPU MEM problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17c346f5-57df-43cf-93bb-ffd36ea1edec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# External Imports\n",
    "from pyspark.sql import functions as SF\n",
    "import pandas as pd\n",
    "\n",
    "# Build Inference Function\n",
    "@SF.pandas_udf(\"string\", SF.PandasUDFType.SCALAR_ITER)\n",
    "def run_distributed_inference(iterator):\n",
    "\n",
    "    # External Imports\n",
    "    from transformers import AutoTokenizer\n",
    "    import ctranslate2\n",
    "    import torch\n",
    "\n",
    "    # Define the paths\n",
    "    local_tokenizer_path = f\"{main_storage_path}/mpt-7b-tokenizer\"\n",
    "    local_model_optimised_path = f\"{main_storage_path}/mpt-7b-ct2\"\n",
    "\n",
    "    # Understand GPU size\n",
    "    total_mem = torch.cuda.get_device_properties(0).total_memory / 1024 ** 2  # in MB\n",
    "    # Decide depending on memory\n",
    "    gpu_type = \"small\" if total_mem < 70000 else \"large\"\n",
    "    \n",
    "    # Params\n",
    "    temperature = 0.1\n",
    "    max_new_tokens = 200\n",
    "    batch_size = 10 if gpu_type == \"large\" else 2\n",
    "    repetition_penalty = 1.05\n",
    "    top_k = 50\n",
    "    top_p = 0.9\n",
    "\n",
    "    # Load the tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(local_tokenizer_path, padding_side=\"left\")\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    # Load the model\n",
    "    mpt_optimised_model = ctranslate2.Generator(\n",
    "        model_path=local_model_optimised_path,\n",
    "        device=\"cuda\",\n",
    "        device_index=0,\n",
    "        compute_type=\"bfloat16\"\n",
    "    )\n",
    "\n",
    "    for requests in iterator:\n",
    "        # Encode requests with tokenizer\n",
    "        batch_tokens = [tokenizer.encode(x) for x in requests.to_list()]\n",
    "        batch_tokens = [tokenizer.convert_ids_to_tokens(ids) for ids in batch_tokens]\n",
    "\n",
    "        # Batch results\n",
    "        batch_results = mpt_optimised_model.generate_batch(\n",
    "            batch_tokens,\n",
    "            max_batch_size=batch_size,\n",
    "            max_length=max_new_tokens,\n",
    "            include_prompt_in_result=False,\n",
    "            sampling_temperature=temperature,\n",
    "            sampling_topk=top_k,\n",
    "            sampling_topp=top_p,\n",
    "            repetition_penalty=repetition_penalty,\n",
    "        )\n",
    "\n",
    "        # Batch decode\n",
    "        decoded_results = [tokenizer.decode(x.sequences_ids[0]) for x in batch_results]\n",
    "\n",
    "        yield pd.Series(decoded_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aee94280-ce76-45eb-92be-8dccc28a2632",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Run Inference\n",
    "\n",
    "Applying the inference function we created on our dataframe, and extracting results. Same with the last notebook, don't forget to adjust the repartition count depending on the number of workers you have in your cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "344da05d-d3c6-4de9-bc55-5af61f4762e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# Auto get number of workers\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "# Subtract 1 to exclude the driver\n",
    "num_workers = len(sc._jsc.sc().statusTracker().getExecutorInfos()) - 1  \n",
    "\n",
    "# Repartition with respect to number of workers\n",
    "condense_df = condense_df.repartition(num_workers)\n",
    "\n",
    "# Set the batch size for the Pandas UDF\n",
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", num_workers*1000)\n",
    "\n",
    "# Run inference\n",
    "condense_df = condense_df.withColumn(\n",
    "    \"condensed_review_summary\", run_distributed_inference(SF.col(\"model_instruction\"))\n",
    ")\n",
    "\n",
    "# Select only the required columns\n",
    "condense_df = condense_df.select(\n",
    "    \"asin\",\n",
    "    \"title\",\n",
    "    \"author\",\n",
    "    \"week_start\",\n",
    "    \"star_rating_class\",\n",
    "    \"condensed_review_summary\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17e2ead0-f8be-422e-acba-2a911e4a8b77",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Merge Condensed with Summarised\n",
    "\n",
    "Now that we have condensed our summaries, we can go ahead and merge the condensed summaries back to our main dataframe, and then build a new column to capture them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8069f726-df7b-4026-bfe3-63a75de3ab53",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join the condense dataframe back to summarised\n",
    "agg_summarised_df = (\n",
    "    agg_summarised_df\n",
    "    .join(\n",
    "        condense_df, \n",
    "        how=\"left\", \n",
    "        on=[\"asin\", \"title\", \"author\", \"week_start\", \"star_rating_class\"]\n",
    "    )\n",
    "    # Build a new column for the final result\n",
    "    .withColumn(\n",
    "        \"final_review_summary\",\n",
    "        # Take the condensed version if it required condensing\n",
    "        SF.when(SF.col(\"needs_condensing\") == True, SF.col(\"condensed_review_summary\"))\n",
    "        # Take the regular version otherwise\n",
    "        .otherwise(SF.col(\"review_summary\"))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48bdf439-b5e0-417b-a2b1-96a22ade7180",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Save Condensed Summaries\n",
    "\n",
    "Our work is done, and is ready to be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d164b47c-a1b3-4166-866c-891168e39265",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    agg_summarised_df\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(\"book_reviews_condensed\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05-condensation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
