{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "afd5b4af-07b0-4f39-800d-fb24dfb61517",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Data Preparation\n",
    "\n",
    "Given that we have our raw dataframes ready, we will now use this notebook to do some exploration and pre-preocessing work to prepare our datasets.\n",
    "\n",
    "What we are aiming for here is to bring the data into a format which we can use with an LLM so that it is in a \"ready to be summarised state\". We will try to achieve this by first sampling reviews in a logical way to be able to capture the good and the bad aspects of the books we have got, and then build a text that contains multiple reviews to summarised.\n",
    "\n",
    "Our ultimate goal is to build tis summariser pipeline so we can have a **faster time to action** after we receive reviews, which can be considered as feedback on our products. Therefore, we need to make sure that we capture the most we can from the reviews, which means that we need to pay attention to both good and bad reviews, and prepare our data so that a good amount of both sides make it through. This is quite important from a sampling perspective, because chances are **most products recieve more positive reviews than negative** (hinting at an inbalanced dataset), so if we straight up implement a generic sampler, we might loose a good proportion of the negative reviews recieved by the products.\n",
    "\n",
    "We also need to ensure that the piece of text we are going to send to the LLM doesn't contain too much text, which has to do with the **context lenghts** - most of the LLMs' performance begin to degrade with longer context lengths both from an quality perspective (how good is the summary?) and performance perspective (how fast can it run?). So, we need to slice and dice our reviews in a respective way to create sensible batches of reviews.\n",
    "\n",
    "Lets begin!\n",
    "\n",
    "\n",
    "**Setup Used:**\n",
    "\n",
    "- Runtime: 13.2 ML\n",
    "- Cluster:\n",
    "  - Machine: 16 CPU + 64 GB RAM (For Driver & Worker)\n",
    "  - 2-8 Worker Auto Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4bb19e71-e520-40cc-8b9d-4394ade5af17",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02-data-prep",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
